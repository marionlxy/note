- Logstash
  - Logstash概述
    - [集中、转换和存储数据](https://app.yinxiang.com/shard/s68/nl/14474728/true)
    - [输入、过滤器和输出](https://app.yinxiang.com/shard/s68/nl/14474728/true)
    - [采集各种样式、大小和来源的数据 （输入）](https://app.yinxiang.com/shard/s68/nl/14474728/true)
    - [实时解析和转换数据 (过滤器)](https://app.yinxiang.com/shard/s68/nl/14474728/true)
  - [选择您的存储库，导出您的数据 (输出)](https://app.yinxiang.com/shard/s68/nl/14474728/true)
  - 下载安装
    - [filebeat 到 logstash](https://app.yinxiang.com/shard/s68/nl/14474728/true)
  - Nginx 日志过滤日志
    - [分析一波](https://app.yinxiang.com/shard/s68/nl/14474728/true)
  - [生产环境使用 supervisor 守护进程启动](https://app.yinxiang.com/shard/s68/nl/14474728/true)
  - [kibana 通过聚合函数 获取分析 PV UV 等数据](https://app.yinxiang.com/shard/s68/nl/14474728/true)

# Logstash

## Logstash概述

### 集中、转换和存储数据

Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。

[下载](https://app.yinxiang.com/OutboundRedirect.action?dest=https%3A%2F%2Fwww.elastic.co%2Fcn%2Fdownloads%2Flogstash)

### 输入、过滤器和输出

Logstash 能够动态地采集、转换和传输数据，不受格式或复杂度的影响。利用 Grok 从非结构化数据中派生出结构，从 IP 地址解码出地理坐标，匿名化或排除敏感字段，并简化整体处理过程。

### 采集各种样式、大小和来源的数据 （输入）

数据往往以各种各样的形式，或分散或集中地存在于很多系统中。 Logstash 支持 [各种输入选择](https://app.yinxiang.com/OutboundRedirect.action?dest=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Flogstash%2Fcurrent%2Finput-plugins.html) ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据。

### 实时解析和转换数据 (过滤器)

数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。

- 利用 Grok 从非结构化数据中派生出结构

- 从 IP 地址破译出地理坐标

- 将 PII 数据匿名化，完全排除敏感字段

- 简化整体处理，不受数据源、格式或架构的影响

  我们的[过滤器库](https://app.yinxiang.com/OutboundRedirect.action?dest=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Flogstash%2Fcurrent%2Ffilter-plugins.html)丰富多样，拥有无限可能。

## 选择您的存储库，导出您的数据 (输出)

尽管 Elasticsearch 是我们的首选输出方向，能够为我们的搜索和分析带来无限可能，但它并非唯一选择。

Logstash 提供[众多输出选择](https://app.yinxiang.com/OutboundRedirect.action?dest=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Flogstash%2Fcurrent%2Foutput-plugins.html)，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。

从 Logstash 的名字就能看出，它主要负责跟日志相关的各类操作，在此之前，我们先来看看日志管理的三个境界吧

```
境界一 
『昨夜西风凋碧树。独上高楼，望尽天涯路』，在各台服务器上用传统的 linux 工具（如 cat, tail, sed, awk, grep 等）对日志进行简单的分析和处理，基本上可以认为是命令级别的操作，成本很低，速度很快，但难以复用，也只能完成基本的操作。

境界二 
『衣带渐宽终不悔，为伊消得人憔悴』，服务器多了之后，分散管理的成本变得越来越多，所以会利用 rsyslog 这样的工具，把各台机器上的日志汇总到某一台指定的服务器上，进行集中化管理。这样带来的问题是日志量剧增，小作坊式的管理基本难以满足需求。

境界三 
『众里寻他千百度，蓦然回首，那人却在灯火阑珊处』，随着日志量的增大，我们从日志中获取去所需信息，并找到各类关联事件的难度会逐渐加大，这个时候，就是 Logstash 登场的时候了
```

Logstash 的主要优势，一个是在支持各类插件的前提下提供统一的管道进行日志处理（就是 input-filter-output 这一套），二个是灵活且性能不错

logstash里面最基本的概念（先不管codec）

logstash收集日志基本流程:

```
input–>filter–>output

input:从哪里收集日志

filter:对日志进行过滤

output:输出哪里
```

![img](http://img.sharkyun.com/blog/2019-07-16-172956.png)

![img](http://img.sharkyun.com/blog/2019-07-16-173010.png)

## 下载安装

```shell
## 解压安装
上传包
tar -xf 包名


cd /opt/logstash-7.2.0
## 启动
./bin/logstash -f 配置文件名

## 后台运行
nohup ./bin/logstash -f  配置文件名  &
```

### filebeat 到 logstash

filebeat 配置

```shell
修改filebeat配置文件中的 output 输出

注释output.elasticsearch数据如下内容：


#output.elasticsearch:
#  # Array of hosts to connect to.
#  hosts: ["localhost:9200"]

去掉注释如下内容

output.logstash:
  #The Logstash hosts
  hosts: ["127.0.0.1:5044"] # 此IP地址或者hosts地址为logstash 地址
```

- logstash 配置

```yaml
## 创建 logstash  配置名称

vim /opt//opt/logstash-7.2.0/logstash_filebeat_exmplate_nginx.yml
## 此配置文件只是检测 filebeat 到 logstash 到ES 是否可以成功 抓取日志
# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
}


output {
    elasticsearch {
      hosts => ["http://localhost:9200"]
      index => "nginx_log-%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}" 
      #user => "elastic"
      #password => "changeme"
    }
}
```

- 启动

```shell
./bin/logstash -f 文件路径自定义/自定义文件名.yml
## 放入后台
使用 nohup /opt/logstash-7.2.0/bin/logstash -f /opt//opt/logstash-7.2.0/logstash_filebeat_exmplate_nginx.yml
```

## Nginx 日志过滤日志



![img](图片\3.01.png)



### 分析一波

抓取日志源 nginx acces_log

python或者 shell 最后目的 PV（反应不出来你的网站的实际情况） UV（真实反馈你网站用户量）HTTP code HTTP请求方式 API接口日志

客户端到服务器的请求时间 $request_time
nginx 负载均衡 或者代理 $upstream_response_time nginx与应用服务器之间的反应

http_referer 次数 网站里面哪个URL 访问量 做相应的调

客户端（useragent）信息 PC 手机 具体使用的浏览器手机型号 产品经理

> 需要修改 nginx log日志格式 (在nginx.conf中添加自定义日志格式)

```shell
## logformat
log_format access '$http_host $remote_addr - $remote_user [$time_local] "$request" '
         '$status $body_bytes_sent "$http_referer" '
         '"$http_user_agent" '
         '$request_time $upstream_response_time '
         '"$http_x_forwarded_for"';


10.36.145.111 10.36.145.45 - - [08/Nov/2019:14:13:38 +0800] "GET /tag/%E8%8B%B1%E9%9B%84 HTTP/1.1" 200 6596 "http://10.36.145.111/tag/Django" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.87 Safari/537.36" 0.030 0.030 "-"
```

> 使用自定义日志格式

```shell
## 在 nginx  server里面添加
access_logs /data/wwwlogs/access.log access;
```

> logstash 配置文件（对应nginx日志文件做grok正则过滤）

```shell
vim /opt/logstash-7.2.0/logstash_filebeat_nginx.yml
input {
   beats {
    port => 5044
   }
}

filter {
           grok {
                   ## grok数据格式整理，可以去官网学习logstash grok格式
                   match => [
                   "message", "%{IPORHOST:http_host} %{IPORHOST:user_ip} - - \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion:float})?|%{DATA:rawrequest})\" %{NUMBER:response:int} (?:%{NUMBER:bytes:int}|-) %{QS:referrer} %{QS:useragent} (?:%{NUMBER:request_time:float}|-) (?:%{NUMBER:upstream_time:float}|-)"
                   ]
           }

     geoip {
                   source => "user_ip"
                   ## 用户IP地址
           }

           date {
                   match => [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
           }
           useragent {
                   target => "ua"
                   source => "useragent"
           }
   }
output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "nginx1-%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  }
}
```

> 启动logstash (加载为不同的配置文件)

```shell
./bin/logstash -f logstash_filebeat_nginx.yml
```

## 生产环境使用 supervisor 守护进程启动

[supervisor守护进程使用](https://app.yinxiang.com/OutboundRedirect.action?dest=https%3A%2F%2Fwww.jianshu.com%2Fp%2Fbf2b3f4dec73)

## kibana 通过聚合函数 获取分析 PV UV 等数据

[kibana 官网文档](https://app.yinxiang.com/OutboundRedirect.action?dest=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fcn%2Fkibana%2Fcurrent%2Findex.html)

1. 先查看获取的index（索引数据），基本的数据分析



![img](D:\千锋             10.36.145.100\note\11.ELK\图片\3.02.png)





![img](图片\3.03.png)



![img](图片\3.04.jpg)



![img](图片\3.05.jpg)



![img](图片\3.06.jpg)



1. 创建PV

PV : 通过nginx每条日志计算数值算作PV数据

![3.07](图片\3.07.png)



![3.08](图片\3.08.jpg)



![3.09](图片\3.09.jpg)



![3.10](图片\3.10.png)

[count帮助文档](https://app.yinxiang.com/OutboundRedirect.action?dest=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2F7.2%2Fsearch-aggregations-metrics-valuecount-aggregation.html)



![3.11](图片\3.11.png)



1. 创建UV



![img](图片\3.12.jpg)



![img](图片\3.13.png)



![img](图片\3.14.png)



1. http状态码



![img](图片\3.15.jpg)



![img](图片\3.16.png)



![img](图片\3.17.png)



1. 客户端类型



![img](图片\3.18.png)





![](图片\3.23.png)



1. 仪表盘



![img](图片\3.19.png)







![img](图片\3.20.jpg)



![img](图片\3.21.png)



![img](图片\3.22.png)