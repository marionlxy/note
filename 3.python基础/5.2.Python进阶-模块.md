##Python进阶: 第三方模块module

-Author: bavdu

-Email: bavduer@163.com

-Github: https://github.com/bavdu

---



##### psutil

---

系统基础信息采集模块作为监控模块的重要组成部分, 能够帮助运维人员了解当前系统的健康程度, 同时也是衡量业务的服务质量的依据, 比如系统资源吃紧, 会直接影响业务的服务质量及用户体验, 另外获取设备的流量信息, 也可以让运维人员更好地评估带宽、设备资源是否应该扩容

psutil 是一个跨平台库, 能够轻松实现获取系统运行的进程和系统利用率(包括CPU、内存、磁盘、网络等)信息, 它主要应用于系统监控, 分析和限制系统资源及进程的管理

psutil安装很简单, 在命令行内使用pip直接安装即可

```python
[root@python ~]# pip3 install psutil
```



- **CPU信息**
  - **User Time,执行用户进程的时间百分比**
  - **System Time,执行内核进程和中断的时间百分比;**
  - **Wait IO,由于IO等待而使CPU处于idle(空闲)状态的时间百分比;**
  - **Idle, CPU处于idle状态的时间百分比;**

```python
import psutil


cpuInfo = psutil.cpu_times()								# 获取cpu完整信息
print('User Time:   ', cpuInfo.user)
print('System Time: ', cpuInfo.system)
print('IOwait Time: ', cpuInfo.iowait)
print('Idle Time:   ', cpuInfo.idle)
cpuCount = psutil.cpu_count()
print('Cpu Count:   ', cpuCount)
```

```python
import psutil
import json


def cpuInfo():
    scputimes = {}
    cpu = psutil.cpu_times()
    scputimes['UserTime'] = cpu.user
    scputimes['SystemTime'] = cpu.system
    scputimes['IOwait'] = cpu.iowait
    scputimes['IdleTime'] = cpu.idle
    return json.dumps(scputimes)
```



- **Memory(信息)**

  **Linux 系统的内存利用率信息涉及 total(内存总数)、used(已使用的内存数)、free(空闲内存数)、buffers(缓冲使用数)、cache(缓存使用数)、swap(交换分区使用数)等.** 

  **分别使用`psutil.virtual_memory()` 与`psutil.swap_memory()` 方法获取这些信息**

```python
import psutil

memInfo = psutil.virtual_memory()			# 获取完整的物理内存信息
print('Memory Total: {:.2f}GB'.format(memInfo.total/1024/1024/1024))
print('Memory Used:  {:.2f}GB'.format(memInfo.used/1024/1024/1024))
print('Memory Free:  {:.2f}GB'.format(memInfo.free/1024/1024/1024))
print('Memory Buffer:{:.2f}GB'.format(memInfo.buffers/1024/1024/1024))
print('Memory Cache: {:.2f}GB'.format(memInfo.cached/1024/1024/1024))

swapInfo = psutil.swap_memory()				# 获取完整的虚拟内存信息
print(swapInfo)
```

```python
import psutil
import json

def memInfo():
    svmem = {}
    memory = psutil.virtual_memory()
    svmem['MemoryTotal'] = memory.total
    svmem['MemoryUsed'] = memory.used
    svmem['MemoryFree'] = memory.free
    svmem['MemoryBuffer'] = memory.buffers
    svmem['MemoryCached'] = memory.cached
    return json.dumps(svmem)
```



- **Disk(信息)**

  - **在系统的所有磁盘信息中, 我们更加关注磁盘的利用率及IO信息, 其中磁盘利用率**

    **使用`psutil.disk_usage`方 法 获 取.** 

  - **磁盘IO信息包括read_count(读 IO 数)、write_count(写IO数)、read_bytes(IO读字节数)       write_bytes(IO 写字节数)、read_time(磁盘读时间)、write_time(磁盘写时间)等.**

    **这些 IO 信息可以使用`psutil.disk_io_counters()` 获取**

```python
diskInfo = psutil.disk_partitions()									# 获取磁盘整体情况
diskUsage = psutil.disk_usage('/')                  # 获取指定分区的使用情况
diskIO = psutil.disk_io_counters()                  # 获取硬盘总的IO个数和读写信息
diskPart = psutil.disk_io_counters(perdisk=True)    # 获取单个硬盘IO个数和读写信息
```



- **Network(信息)**

  - **监控网络的信息主要有`bytes_sent`(发送字节数)、`bytes_recv`(接收字节数)、`packets_sent`(发送数据包数)、`packets_recv`(接收数据包数).** 

    **这些网络信息使用`psutil.net_io_counters()`方法获取**

```python
networkInfo = psutil.net_io_counters()
```



- **psutil(管理进程的方式)**
  - **psutil模块使用psutil.pids()方法获取所有进程PID, 使用psutil.Process()方法获取单个进程的名称、路径、状态、系统资源利用率等信息**

```python
import psutil

allPid = psutil.pids()
# print(allPid)
process = psutil.Process(25766)
print(process.name())               # 获取进程名字
print(process.exe())                # 获取进程执行路径
print(process.status())             # 获取进程状态
print(process.num_threads())        # 获取进程开启的线程数
print(process.create_time())        # 获取进程创建时间
print(process.cpu_times())          # 获取user、system 两个 CPU 时间
print(process.memory_percent())     # 获取进程内存利用率
print(process.memory_info())        # 获取进程内存rss、vms信息
print(process.io_counters())        # 进程IO信息,包括读写IO数及字节数
```



##### paramiko

---

paramiko是基于SSH协议用于连接远程服务器并执行相关操作(SSHClient和SFTPClinet,即远程连接/上传下载务)的服务;   使用该模块可以对远程服务器进行命令或文件操作,  ansible内部的远程管理就是使用的paramiko来现实现的;

```python
# 基于用户名和密码连接远程服务器

import paramiko


client = paramiko.SSHClient()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
client.connect(
    hostname='1.1.1.1',
    port=22,
    username='root',
    password='xxxxxxxx'
)

stdin, stdout, stderr = client.exec_command(command='hostname', timeout=0.03)
print(stdout.read().decode('utf-8'))

client.close()
```

```python
# 基于秘钥对儿连接远程服务器
import paramiko

private = paramiko.RSAKey.from_private_key_file('/Users/chaoliu/.ssh/id_rsa')

client = paramiko.SSHClient()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
client.connect(
    hostname='39.100.110.135',
    port=22,
    username='root',
    password='liuchao.0725'
)

stdin, stdout, stderr = client.exec_command('hostname')
print(stdout.read().decode('utf-8'))

client.close()
```

```python
# 基于加密通道传输
import paramiko

private = paramiko.RSAKey.from_private_key_file('/Users/chaoliu/.ssh/id_rsa')
transport = paramiko.Transport(('39.100.110.135', 22))
transport.connect(username='root', pkey=private)
client = paramiko.SSHClient()
client._transport = transport

stdin, stdout, stderr = client.exec_command('hostname')
print(stdout.read().decode('utf-8'))

transport.close()
```

```python
# 基于加密通道进行上下传文件
import paramiko

private = paramiko.RSAKey.from_private_key_file('/Users/chaoliu/.ssh/id_rsa')
transport = paramiko.Transport(('39.100.110.135', 22))
transport.connect(username='root', pkey=private)

sftp = paramiko.SFTPClient.from_transport(transport)

sftp.put('/Users/chaoliu/Downloads/Books/docker_practice.pdf', '/opt/docker_practice.pdf')

transport.close()
```





##### subprocess

---

subprocess模块主要用于创建子进程, 并连接它们的输入/输出/错误管道, 获取它们的返回状态. 通俗地说就是通过这个模块, 你可以在Python的代码里执行操作系统级别的命令, 比如“ipconfig”、“du -sh”等等;

```python
import subprocess


# 执行系统shell命令
subprocess.run(['du', '-sh'])
subprocess.run('du -sh', shell=True)

# 获取系统shell命令执行后的结果
result = subprocess.run('du -sh', shell=True, stdout=subprocess.PIPE)
print(result, type(result))
```

subprocess.Popen

- args: 命令,可以是字符串或者可迭代对象(列表/元组)
- bufsize: 缓冲区大小(基本用不到)
- stdin,stdout,stderr: 分别表示程序的标准输入/标准输出/标准错误
- shell: 指定是否使用本地系统shell执行命令(True/False)
- cwd: 用于设置子进程的当前目录                                              .Popen('ls', cwd = '/root' , shell = True)
- env: 用于指定子进程的环境变量(默认从父进程继承环境变量)
- universal_newlines: 不同系统的的换行符不同,当该参数设定为true时,则表示使用\n作为换行符

```python
# 在当前目录下创建subtotal目录
subprocess.Popen('mkdir subtotal', shell=True, cwd='Github/pysement')

# 获取命令的输出结果
result = subprocess.Popen(['cat', '/etc/passwd'], stdout=subprocess.PIPE)
print(result.stdout.read())  ## 输出的形式为字节形式  <class 'bytes'>  
result.stdout.close()   ## 只有read的时候才会用 close关闭

# 将子程序的输出, 输入到另一个子程序中
child01 = subprocess.Popen('pip list', shell=True, stdout=subprocess.PIPE)
child02 = subprocess.Popen(['grep', 'paramiko'], stdin=child01.stdout, stdout=subprocess.PIPE)
print(child02.stdout.read())
child02.stdout.close()
```



##### logging日志处理模块

---

```python
import logging

# 定义日志输出的位置/级别/格式/增加规则
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(pathname)s - %(message)s',
  	datefmt='%Y-%m-%d %H:%M:%S',
    level=logging.WARNING,  ##warning 及以上被记录
    filename='./example.log',
    filemode='a'   ##必须是追加 
)

try:
    var01, var02 = 'hello', 18
    print(var01 + var02)
except Exception as error:
    logging.error(error)
finally:
    pass

print('go on ...')
```



- logger日志记录器, 暴露给应用使用的接口
- handlers日志处理器, 发送日志记录到指定的位置
- formatters日志格式化, 日志记录格式

```python
import logging.handlers


# 设置日志的记录格式
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# 1.
# 设置日志处理器,将日志记录器获取的日志放到指定文件
rowHandler = logging.FileHandler(filename='logRecording.log')

# 2.
# 设置日志处理器,将日志记录器获取的日志放到指定文件,并根据大小进行切割
rotateHandler = logging.handlers.RotatingFileHandler(
    filename='logRotate.log',
    maxBytes=1024 * 1024 * 5,  ##最大的大小 5M
    backupCount=5   ##切成几个文件
    
)

# 3.
# 设置日志处理器,将日志记录器获取的日志文件放到指定文件,并根据时间进行切割
timeHandler = logging.handlers.TimedRotatingFileHandler(
    filename='example.log',
    when='D',     ##规定 为天数
    interval=2,    ## 2天一次
    backupCount=5  ## 切成5个
)

#
# 设置日志处理器处理日志的最低级别
rowHandler.setLevel(logging.WARNING)
# 为日志处理器设置格式化器
rowHandler.setFormatter(formatter)

# 设置日志的记录器,并设置记录器的名字
logger = logging.getLogger()       ##记录器的名字   'logRecording'
# 设置日志记录器的最低记录级别
logger.setLevel(logging.WARNING)   ##和日志处理日志的最低级别保持一致
# 为日志记录器添加处理器
logger.addHandler(rowHandler)


try:
    var01, var02 = 'hello', 18
    print(var01 + var02)
except Exception as error:
    logger.error(error)
finally:
    pass

print('go on ...')
```



- logging.conf 配置文件设置日志

```ini
# @project/logconfig.conf
[formatters]
keys=formatOne
[formatter_formatOne]
format=%(asctime)s-%(name)s-%(levelname)s-%(pathname)s-%(message)s
datefmt=%a, %Y-%m-%d %H:%M:%S

[handlers]
keys=file,rotateSize
[handler_file]
class=FileHandler    ##来源于logging
level=DEBUG
formatter=formatOne
args=('logfileName.log', 'a')
[handler_rotateSize]
class=handlers.RotatingFileHandler   ##来源于handkers
level=WARNING
formatter=formatOne
args=('logfileName.log', 'a', 5*1024*1024, 5, None, False)  ##路径 模式 大小 个数  编码 布尔

[loggers]
keys=root,rotate
[logger_root]
handlers=file    ##handler_file 里的内容传给root 处理器
[logger_rotate]
handlers=rotateSize  ##handler_rorareSize 传给rotate
qualname=rotate
propagate=0    ##是否传值到别处  默认0不传
```

```python
import logging.config    ##加载自定义的配置文件

logging.config.fileConfig('./logconfig.ini')  ##自定义配置文件的路径地址

try:
    var01, var02 = 'hello', 18
    print(var01 + var02)
except Exception as error:
    logger = logging.getLogger('rotateSize')
    logger.error(error)
finally:
    pass

print('go on...')
```

